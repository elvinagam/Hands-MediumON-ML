{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bloomberg_feedback.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elvinaqa/Hands-MediumON-ML/blob/master/Bloomberg_Interview_feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkhJvCcUeQVC"
      },
      "source": [
        "# Bloomberg Interview feedback for a AI Research Engineer position\n",
        "25 March 2021\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX9rtNdRq2Ug"
      },
      "source": [
        "## Which model would you like to use for multiclass news topic classification? \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "[DAN](https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf) since it is very fast to train and run and it is fairly accurate. Its accuracy also improves with noise.\n",
        "\n",
        "My PyTorch implementation of it is on my Github [here](https://github.com/Anyulund/NLP/tree/master/Sentiment%20Analysis/DANclassifier). It was done as a part of a graduate NLP class at the University of Texas at Austin. Writing \"How to\" in Readme is a work in process. I am planning to start working on it this next month. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1GxL1b1efBm"
      },
      "source": [
        "## Which activation function should be used in the last layer? \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Sigmoid function formula**\n",
        "\n",
        "$$ \\theta(Z_{j}) = \\frac{ e^Z_{j}}{1+e^Z_{j}}$$\n",
        "\n",
        "If model's ouput classes are not mutually exclusive and one can choose many of them at the same time, it is good to use the sigmoid functions on the nework outputs. The sigmoid will allow to have high probability for all of the cases, some of them or none of them. \n",
        "\n",
        "Hence the correction here is that for multiclass topic news classifier this would be a good function to use in the last activation layer. Since there are multiple classes, the input of the weight would be equal to the amount of classes in the last layer. Since there are two labels per each input, the weight would be equal double the amount of inputs in the first layer.\n",
        "\n",
        "More details are in [Machine Learning Mastery](https://machinelearningmastery.com/multi-label-classification-with-deep-learning/)\n",
        "\n",
        "**Softmax function formula**\n",
        "\n",
        "Softmax is a generaliaztion of sigmoid function. It was developed as smoothed and differentiable alternative to the argmax function. Because of this the softmax function is sometimes more explicitly called the softargmax function.\n",
        "\n",
        "$$s = \\frac{e^z_{j}}{sum_{k=1}^K e^zk} \\textrm{ for } j=1,..,K $$ \n",
        "\n",
        "If models output classes are mutually exlusive, and one can choose only one, softmax function should be used. \n",
        "\n",
        "So per topic news classifier in theory this function could be used with multiple different models in a sequence, and then a ranking or sorting algorithm could be used. Whether this method is worth to be considered is on my \"to be determined\" list.  \n",
        "\n",
        "**Argmax function formula**\n",
        "\n",
        "$$x^* = arg\\ max f(x)   $$\n",
        "\n",
        "It returns x that maximizes $$f(x)$$\n",
        "\n",
        "According to [deepai.org](https://deepai.org/machine-learning-glossary-and-terms/softmax-layer#:~:text=Softmax%20Function%20vs%20Argmax%20Function&text=Like%20the%20softmax%2C%20the%20argmax,value%2C%20where%20it%20returns%201.&text=We%20must%20use%20softmax%20in,to%20optimize%20a%20cost%20function.)\n",
        "like the softmax, the argmax function operates on a vector and converts every value to zero except the maximum value, where it returns 1.\n",
        "\n",
        "It is common to train a machine learning model using the softmax but switch out the softmax layer for an argmax layer when the model is used for inference.\n",
        "\n",
        "We must use softmax in training because the softmax is differentiable and it allows us to optimize a cost function. However, for inference sometimes we need a model just to output a single predicted value rather than a probability, in which case the argmax is more useful.\n",
        "\n",
        "When there are multiple maximum values it is common for the argmax to return $$ \\frac{1}{N_{max}}$$, that is a normalized fraction, so that the sum of the output elements remains 1 as with the softmax. An alternative definition is to return 1 for all maximum values, or for the first value only.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc-QXhFDpXbt"
      },
      "source": [
        "## Clarification on word embeddings \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "For multiclass classification in the present case, I would use Flair. I like this library, because:\n",
        "\n",
        "* It comprises of popular and state-of-the-art word embeddings, such as GloVe, BERT, ELMo, Character Embeddings, etc. There are very easy to use thanks to the Flair API\n",
        "* Flair’s interface allows us to combine different word embeddings and use them to embed documents. This in turn leads to a significant uptick in results\n",
        "* ‘Flair Embedding’ is the signature embedding provided within the Flair library. It is powered by contextual string embeddings. We’ll understand this concept in detail in the next section\n",
        "* Flair supports a number of languages – and is always looking to add new ones\n",
        "\n",
        "If sentiment analysis is done on positive or negative reviews or resume classificaiton (for which deep learning is not recommended), I recommend to use [ConceptNet](http://blog.conceptnet.io/posts/2017/conceptnet-numberbatch-17-04-better-less-stereotyped-word-vectors/) word embeddings.\n",
        "\n",
        "[Here](https://github.com/Anyulund/NLP/blob/master/Word_Embeddings/Exploring_word_vectors.ipynb) is my latest work on word embeddings as a part of Stanford NLP class. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSwJ6Szz9PoU"
      },
      "source": [
        "## Addressing The Issue of the Black Box of Deep Learning Models\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "This is a very challenging topic. Finding different ways to have a more human-friendly explanations is one of the topics in **Interpretable Machine Learning - A Guide for Making Black Box Models Explainable** by *Christoph Molnar*. The link to this book is [here]((https://christophm.github.io/interpretable-ml-book/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEMfkQzWvDI2"
      },
      "source": [
        "## Remove Unbalanced Parenthesis\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This is a hard level problem on Leetcode. For its solution I chose to implement my previous Leetcode practice, which can be viewed [here](https://github.com/Anyulund/Python-practice)\n",
        "\n",
        "I chose to have 3 different functions for the solution: \n",
        "\n",
        "1. isParenthesis(c) to check if the input is actually left or right parenthesis\n",
        "2. isValid(s) to check if the combinations of the parentheses and its order are valid in the string. I solved this Leetcode problem two weeks ago, and is implementation can be seen in my GitHub link from above. \n",
        "3. RemoveInvalidParenthesis(s). This function incorporates the above to functions and uses Breadth First Search to implement the solution. I chose to use collection package to create deque since it gives an advantage by using appendleft feature. \n",
        "4. Then I used doctest function to run different test cases. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtqWjNEPsU6U"
      },
      "source": [
        "def isParenthesis(c):\n",
        "    '''Function checks if there is left or right parenthesis.\n",
        "  >>> isParenthesis(\"(\")\n",
        "  True\n",
        "  >>> isParenthesis(\"\")\n",
        "  False\n",
        "  >>> isParenthesis(\" \")\n",
        "  False\n",
        "  >>> isParenthesis(\")\")\n",
        "  True\n",
        "  '''\n",
        "    return ((c == '(') or (c == ')')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNa850NWvl05"
      },
      "source": [
        "I modified my previous solution to fit this problem. The original solution to this problem is below: \n",
        "```python\n",
        "\n",
        "def isValid(string):\n",
        "  if (len(string)%2 != 0) or (len(string)==0):\n",
        "    return False\n",
        "\n",
        "  ps = []\n",
        "  hashmap = dict({\"[\": \"]\", \"(\": \")\", \"{\": \"}\"})\n",
        "\n",
        "  for ind,elem in enumerate(string): \n",
        "    if elem == \"(\" or elem == \"[\" or elem == \"{\":\n",
        "      ps.append(elem)\n",
        "    else:\n",
        "        if len(ps) == 0 or elem != hashmap[ps[-1]]:\n",
        "          return False \n",
        "        else: \n",
        "          ps.pop()               \n",
        "  return len(ps) == 0\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HElF7Lyx0ML4"
      },
      "source": [
        "This is modified solution to solve the new problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUPYSV9BeeGh"
      },
      "source": [
        "def isValid(s):\n",
        "  '''Function checks if the sequence of parenthesis is valid, \n",
        "  i.e all left parenthesis are matched with the right ones.\n",
        "  >>> isValid(\"()\")\n",
        "  True\n",
        "  >>> isValid(\"(())\")\n",
        "  True\n",
        "  >>> isValid(\"()()\")\n",
        "  True\n",
        "  >>> isValid(\"(\")\n",
        "  False\n",
        "  >>> isValid(\")\")\n",
        "  False\n",
        "'''\n",
        "\n",
        "  if (len(s)%2 != 0):\n",
        "    return False\n",
        "\n",
        "  ps = []\n",
        "  hashmap = dict({ \"(\": \")\"})\n",
        "  \n",
        "  for ind,elem in enumerate(s): \n",
        "    if elem == \"(\":\n",
        "      ps.append(elem)\n",
        "    else:\n",
        "        if len(ps) == 0 or elem != hashmap[ps[-1]]:\n",
        "          return False \n",
        "        else: \n",
        "          ps.pop()   \n",
        "\n",
        "  return len(ps) == 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbu_b9287bwe"
      },
      "source": [
        "I chose Breadth First Search to implement the solution to remove invalid parenthesis.The implementaion of BFS in Python can be found [here](https://ksvi.mff.cuni.cz/~dingle/2019/algs/lecture_12.html#breadth-first%20search|outline)\n",
        "To implement a breadth-first search in Python, we need a queue data structure. We can conveniently use the deque (double-ended queue) class found in the collections module. Since a deque is double-ended, we can use it as a queue in either of two ways: we can either\n",
        "\n",
        "    call d.appendleft() to enqueue, and d.pop() to dequeue, or\n",
        "\n",
        "    call d.append() to enqeue, and d.popleft() to dequeue\n",
        "\n",
        "All of these dequeue operations are fast, so these approaches should be equally efficient, and we can choose one arbitrarily.\n",
        "\n",
        "Here is a Python function bfs() that performs a breadth-first search. It takes a graph in adjacency-list representation, plus a start vertex:\n",
        "```python\n",
        "import collections\n",
        "\n",
        "# breadth-first search\n",
        "def bfs(g, start):\n",
        "    q = deque()\n",
        "    q.appendleft(start)   # enqueue\n",
        "    visited = { start }\n",
        "    \n",
        "    while q:\n",
        "        node = q.pop()\n",
        "        print('exploring ' + node)\n",
        "        for n in g[node]:\n",
        "            if n not in visited:\n",
        "                visited.add(n)\n",
        "                q.appendleft(n)   # enqueue\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdOvPoVz0oG6"
      },
      "source": [
        "This is a modified solution for this particular problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pscdWGttc9F6"
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "visited = set() # Set to keep track of visited nodes.\n",
        "queue = []      # Initialize a queue\n",
        "\n",
        "\n",
        "def removeInvalidParenthesis(s):\n",
        "    '''Function removes all unbalanced parenthesis.\n",
        "  >>> removeInvalidParenthesis(\"()\")\n",
        "  ()\n",
        "  >>> removeInvalidParenthesis(\"(())\")\n",
        "  (())\n",
        "  >>> removeInvalidParenthesis(\"()()\")\n",
        "  ()()\n",
        "  >>> removeInvalidParenthesis(\"(\")\n",
        "  <BLANKLINE>\n",
        "  >>> removeInvalidParenthesis(\")\")\n",
        "  <BLANKLINE>\n",
        "  >>> removeInvalidParenthesis(\")(\")\n",
        "  <BLANKLINE>\n",
        "  >>> removeInvalidParenthesis(\"(()\")\n",
        "  ()\n",
        "  '''\n",
        "    if (len(s) == 0):\n",
        "        return\n",
        "\n",
        "    neighbour = 0\n",
        "    level = 0\n",
        "\n",
        "\n",
        "    q = deque()\n",
        "    q.appendleft(s)   # enqueue\n",
        "    visited = {s}\n",
        " \n",
        "    while q:\n",
        "        s = q.pop()\n",
        "        if (isValid(s)):\n",
        "          print(s)           \n",
        "          # If answer is found, make level true \n",
        "          # so that valid of only that level \n",
        "          # are processed. \n",
        "          level = True\n",
        "        if (level):\n",
        "          continue\n",
        "        for ind, neighbour in enumerate(s):\n",
        "            if (not isParenthesis(neighbour)):\n",
        "              continue\n",
        "            # Removing parenthesis from str and \n",
        "            # pushing into queue,if not visited already \n",
        "            neighbour = s[0:ind] + s[ind + 1:] \n",
        "            if neighbour not in visited:\n",
        "                visited.add(neighbour)\n",
        "                q.appendleft(neighbour)   # enqueue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub1tSkNS6Q9N"
      },
      "source": [
        "# call the testmod function\n",
        "import doctest\n",
        "if __name__ == '__main__':\n",
        "    doctest.testmod()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPvRgyCFttbx"
      },
      "source": [
        "I enjoyed the interview process and learned a lot from it. Todays interiew helped me:\n",
        "\n",
        "1. To deepen my understanding of Softmax, Sigmoid and Armax functions. \n",
        "2. Helped me understand how to build classifier that have more than one output for each input \n",
        "3. Introduced me to Breadth-First Search \n",
        "4. Helped me to discover new learning materials on algorithms in Python that I had difficulties finding\n",
        "\n",
        "If I get a feedback from a recruiter, I would love to hear suggestions on new materials and path to improvement. \n",
        "\n",
        "Thank you,\n",
        "Anna Nyulund"
      ]
    }
  ]
}