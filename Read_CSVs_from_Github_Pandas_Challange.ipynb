{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Read CSVs from Github Pandas Challange",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elvinaqa/Hands-MediumON-ML/blob/master/Read_CSVs_from_Github_Pandas_Challange.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B8m86LAyRUY"
      },
      "source": [
        "[Original Challange]()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMhSrEP4iyuD"
      },
      "source": [
        "!git clone https://github.com/abhishekkrthakur/csv_test.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FssH72_VDmGD"
      },
      "source": [
        "# shameless advertising ;)\n",
        "CONNECT_WORKER = False\n",
        "if CONNECT_WORKER:\n",
        "    !pip install clearml-agent\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    !cp /content/drive/My\\ Drive/clearml.conf ~\n",
        "    !clearml-agent daemon --queue colab\n",
        "else:\n",
        "    # will use the demo server unless configured\n",
        "    !pip install clearml\n",
        "    from clearml import Task\n",
        "    task = Task.init('the csv challange','twitter challanges')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRWulUaj9Y8"
      },
      "source": [
        "%cd /content/csv_test/\r\n",
        "from pathlib import Path\r\n",
        "files = [p for p in Path('data/').glob('*.csv')]\r\n",
        "files.sort(key = lambda p : int(p.stem))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnmDSaz9DneY"
      },
      "source": [
        "!pip install pandas\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "USE_PANDAS = False\r\n",
        "# The pandas way - don't do it, it will crash the runtime\r\n",
        "if USE_PANDAS:\r\n",
        "    def pure_pandas(file_list):\r\n",
        "        return pd.concat([pd.read_csv(f) for f in file_list])\r\n",
        "else:\r\n",
        "    def pure_pandas(*args):\r\n",
        "        return None\r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "%timeit pure_pandas(files[:5000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEWRRrojkKyQ"
      },
      "source": [
        "import csv\r\n",
        "\r\n",
        "# copy pasted form stackoverflow otherwise pip install more_itertools\r\n",
        "def chunked(lst, n):\r\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\r\n",
        "    for i in range(0, len(lst), n):\r\n",
        "        yield lst[i:i + n]\r\n",
        "\r\n",
        "def pure_csv(flist, chunksize=30000):\r\n",
        "    with open('answer.csv',mode='w') as output:\r\n",
        "        writer = csv.writer(output)\r\n",
        "        # first file\r\n",
        "        with open(flist[0],'r',newline='') as f1:\r\n",
        "            reader = csv.reader(f1)\r\n",
        "            rows = [r for r in reader]\r\n",
        "        for r in rows:\r\n",
        "            writer.writerow(r)\r\n",
        "        # rest is chunked\r\n",
        "        if len(flist) > chunksize:\r\n",
        "            chunks = chunked(flist[1:], chunksize)\r\n",
        "        else:\r\n",
        "            chunks = [flist[1:]]\r\n",
        "            \r\n",
        "        for this_chunk in chunks:\r\n",
        "            rows = []\r\n",
        "            for f in this_chunk:\r\n",
        "                with open(f,'r',newline='') as input:\r\n",
        "                    reader = csv.reader(input)\r\n",
        "                    next(reader)\r\n",
        "                    rows.extend([r for r in reader])\r\n",
        "            for r in rows:\r\n",
        "                writer.writerow(r)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrUiPW-v6ttz"
      },
      "source": [
        "%timeit pure_csv(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hdu44ukMfqW"
      },
      "source": [
        "ans.info()\n",
        "ans = pd.read_csv('answer.csv')\n",
        "del ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF3XfK3CWKjW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}