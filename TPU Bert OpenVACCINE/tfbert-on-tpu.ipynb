{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport copy\nimport tensorflow.keras.layers as L\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import regularizers\n\nfrom sklearn.model_selection import train_test_split, KFold, RepeatedStratifiedKFold, StratifiedKFold\nfrom transformers import BertTokenizer, TFBertModel, BertConfig, BertModel, TFDistilBertModel, DistilBertConfig","execution_count":1,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def seed_everything(seed = 34):\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nseed_everything()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nsub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n\n#target columns\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MCRMSE(y_true, y_pred):\n    columnwise_mse = tf.reduce_mean(tf.square(y_true-y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=1)\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":5,"outputs":[{"output_type":"stream","text":"Running on TPU  grpc://10.0.0.2:8470\nREPLICAS:  8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = DistilBertConfig() \n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config.vocab_size = 10\nconfig.dim = 128\nconfig.hidden_dim = 128\nconfig.max_position_embeddings = 128\nconfig.n_layers = 2\nconfig.n_heads = 1\nconfig.sinusoidal_pos_embds = True","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.GRU(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n\ndef lstm_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.LSTM(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr = 1e-3\n# max_grad_norm = 1.0\n# num_training_steps = 1000\n# num_warmup_steps = 100\n# warmup_proportion = float(num_warmup_steps) / float(num_training_steps)  # 0.1\n# optimizer = BertAdam(model.parameters(), lr=lr, schedule='warmup_linear', warmup=warmup_proportion, num_training_steps=100)","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(transformer, seq_len=107, pred_len=68, dropout=0.5, embed_dim=100, hidden_dim=128):\n    ids = L.Input(shape=(seq_len,3),  dtype=tf.int32, name=\"input_word_ids\")\n    flat = L.Flatten()(ids)\n    sequence_output = transformer(flat)[0]\n    \n    truncated = sequence_output[:,:pred_len, :]\n    \n    out = L.Dense(32, activation='relu')(truncated)\n\n    out = L.Dense(5, activation='linear')(out)\n    model = tf.keras.Model(inputs=ids, outputs=out)\n\n    model.compile('adam', loss=MCRMSE)\n    \n    return model","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    transformer_layer = (\n        TFDistilBertModel(config=config)\n    )\n    model = build_model(transformer_layer)\nmodel.summary()\n","execution_count":61,"outputs":[{"output_type":"stream","text":"Model: \"model_29\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_word_ids (InputLayer)  [(None, 107, 3)]          0         \n_________________________________________________________________\nflatten_29 (Flatten)         (None, 321)               0         \n_________________________________________________________________\ntf_distil_bert_model_5 (TFDi ((None, 321, 128),)       217088    \n_________________________________________________________________\ntf_op_layer_strided_slice_29 [(None, 68, 128)]         0         \n_________________________________________________________________\ndense_33 (Dense)             (None, 68, 32)            4128      \n_________________________________________________________________\ndense_34 (Dense)             (None, 68, 5)             165       \n=================================================================\nTotal params: 221,381\nTrainable params: 221,381\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokentoint = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [tokentoint[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\npreprocess_inputs(train).shape","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"(2400, 107, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = preprocess_inputs(train[train['signal_to_noise'] >= 1])\ntrain_labels = np.array(train[train['signal_to_noise'] >= 1][target_cols].values.tolist()).transpose(0, 2, 1)\n","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_inputs.shape)\nprint(train_labels.shape)\n","execution_count":64,"outputs":[{"output_type":"stream","text":"(2097, 107, 3)\n(2097, 68, 5)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_df = test[test['seq_length']==107].copy()\nprivate_df = test[test['seq_length']==130].copy()\n\npublic_inputs = preprocess_inputs(public_df)\nprivate_inputs = preprocess_inputs(private_df)\n","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#basic training configuration\nFOLDS = 5\nEPOCHS = 70\nREPEATS = 1\nBATCH_SIZE = 64\nVERBOSE = 2\nSEED = 34\n","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau()","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_histories = []\nbert_private_preds = np.zeros((private_df.shape[0], 130, 5))\nbert_public_preds = np.zeros((public_df.shape[0], 107, 5))\n\nkf = KFold(n_splits=FOLDS,shuffle=True,random_state=42)\n\n\nwith strategy.scope():\n   \n    \n    for fold, (train_index, val_index) in enumerate(kf.split(train_inputs, train_labels)):\n        print(f\"FOLD {fold}\")\n        \n        model = build_model(transformer_layer)\n        \n        history = model.fit(\n            train_inputs[train_index,:,:], train_labels[train_index,:,:], \n            batch_size=BATCH_SIZE,\n            epochs=EPOCHS,\n            validation_split=0.1,\n                callbacks=[\n                            lr_callback,\n                            tf.keras.callbacks.ModelCheckpoint('model'+str(fold)+'.h5',save_weights_only=True,save_best_only=True)\n                            ])\n\n        model_short = build_model(transformer_layer,seq_len=107, pred_len=107)\n        model_long = build_model(transformer_layer,seq_len=130, pred_len=130)\n\n        model_short.load_weights('model'+str(fold)+'.h5')\n        model_long.load_weights('model'+str(fold)+'.h5')\n        \n        bert_histories.append(history)\n\n        bert_public_pred = model_short.predict(public_inputs) / FOLDS\n\n        bert_private_pred = model_long.predict(private_inputs) / FOLDS\n\n        bert_public_preds += bert_public_pred\n        bert_private_preds += bert_private_pred\n        \n","execution_count":68,"outputs":[{"output_type":"stream","text":"FOLD 0\nEpoch 1/70\n24/24 [==============================] - 6s 256ms/step - loss: 0.5619 - val_loss: 0.4312 - lr: 0.0010\nEpoch 2/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.4160 - val_loss: 0.4201 - lr: 0.0010\nEpoch 3/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.4093 - val_loss: 0.4199 - lr: 0.0010\nEpoch 4/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.4075 - val_loss: 0.4143 - lr: 0.0010\nEpoch 5/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.4047 - val_loss: 0.4119 - lr: 0.0010\nEpoch 6/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.4028 - val_loss: 0.4099 - lr: 0.0010\nEpoch 7/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.4004 - val_loss: 0.4111 - lr: 0.0010\nEpoch 8/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3999 - val_loss: 0.4146 - lr: 0.0010\nEpoch 9/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3996 - val_loss: 0.4098 - lr: 0.0010\nEpoch 10/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.3988 - val_loss: 0.4095 - lr: 0.0010\nEpoch 11/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3983 - val_loss: 0.4096 - lr: 0.0010\nEpoch 12/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3973 - val_loss: 0.4079 - lr: 0.0010\nEpoch 13/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3951 - val_loss: 0.4107 - lr: 0.0010\nEpoch 14/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3943 - val_loss: 0.4050 - lr: 0.0010\nEpoch 15/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3936 - val_loss: 0.4056 - lr: 0.0010\nEpoch 16/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3919 - val_loss: 0.4049 - lr: 0.0010\nEpoch 17/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3915 - val_loss: 0.4017 - lr: 0.0010\nEpoch 18/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3905 - val_loss: 0.4053 - lr: 0.0010\nEpoch 19/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3896 - val_loss: 0.4004 - lr: 0.0010\nEpoch 20/70\n24/24 [==============================] - 1s 29ms/step - loss: 0.3887 - val_loss: 0.4024 - lr: 0.0010\nEpoch 21/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3883 - val_loss: 0.3982 - lr: 0.0010\nEpoch 22/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3870 - val_loss: 0.3982 - lr: 0.0010\nEpoch 23/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.3867 - val_loss: 0.3963 - lr: 0.0010\nEpoch 24/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3862 - val_loss: 0.3971 - lr: 0.0010\nEpoch 25/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.3843 - val_loss: 0.3940 - lr: 0.0010\nEpoch 26/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3823 - val_loss: 0.3912 - lr: 0.0010\nEpoch 27/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3788 - val_loss: 0.3880 - lr: 0.0010\nEpoch 28/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3776 - val_loss: 0.3868 - lr: 0.0010\nEpoch 29/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3757 - val_loss: 0.3843 - lr: 0.0010\nEpoch 30/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3739 - val_loss: 0.3806 - lr: 0.0010\nEpoch 31/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3716 - val_loss: 0.3795 - lr: 0.0010\nEpoch 32/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3705 - val_loss: 0.3751 - lr: 0.0010\nEpoch 33/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3705 - val_loss: 0.3770 - lr: 0.0010\nEpoch 34/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.3679 - val_loss: 0.3746 - lr: 0.0010\nEpoch 35/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3664 - val_loss: 0.3718 - lr: 0.0010\nEpoch 36/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3651 - val_loss: 0.3722 - lr: 0.0010\nEpoch 37/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3645 - val_loss: 0.3696 - lr: 0.0010\nEpoch 38/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3625 - val_loss: 0.3694 - lr: 0.0010\nEpoch 39/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3619 - val_loss: 0.3674 - lr: 0.0010\nEpoch 40/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3621 - val_loss: 0.3701 - lr: 0.0010\nEpoch 41/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3609 - val_loss: 0.3667 - lr: 0.0010\nEpoch 42/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3611 - val_loss: 0.3695 - lr: 0.0010\nEpoch 43/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3595 - val_loss: 0.3637 - lr: 0.0010\nEpoch 44/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3575 - val_loss: 0.3660 - lr: 0.0010\nEpoch 45/70\n24/24 [==============================] - 1s 29ms/step - loss: 0.3563 - val_loss: 0.3659 - lr: 0.0010\nEpoch 46/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3565 - val_loss: 0.3626 - lr: 0.0010\nEpoch 47/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3579 - val_loss: 0.3607 - lr: 0.0010\nEpoch 48/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3548 - val_loss: 0.3613 - lr: 0.0010\nEpoch 49/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3536 - val_loss: 0.3604 - lr: 0.0010\nEpoch 50/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3526 - val_loss: 0.3580 - lr: 0.0010\nEpoch 51/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3516 - val_loss: 0.3580 - lr: 0.0010\nEpoch 52/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3506 - val_loss: 0.3568 - lr: 0.0010\nEpoch 53/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3509 - val_loss: 0.3546 - lr: 0.0010\nEpoch 54/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3495 - val_loss: 0.3531 - lr: 0.0010\nEpoch 55/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3477 - val_loss: 0.3528 - lr: 0.0010\nEpoch 56/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3463 - val_loss: 0.3534 - lr: 0.0010\nEpoch 57/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3465 - val_loss: 0.3613 - lr: 0.0010\nEpoch 58/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3456 - val_loss: 0.3548 - lr: 0.0010\nEpoch 59/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3441 - val_loss: 0.3521 - lr: 0.0010\nEpoch 60/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3432 - val_loss: 0.3500 - lr: 0.0010\nEpoch 61/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3435 - val_loss: 0.3512 - lr: 0.0010\nEpoch 62/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3420 - val_loss: 0.3503 - lr: 0.0010\nEpoch 63/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3429 - val_loss: 0.3496 - lr: 0.0010\nEpoch 64/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.3419 - val_loss: 0.3472 - lr: 0.0010\nEpoch 65/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3398 - val_loss: 0.3474 - lr: 0.0010\nEpoch 66/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3390 - val_loss: 0.3476 - lr: 0.0010\nEpoch 67/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3383 - val_loss: 0.3444 - lr: 0.0010\nEpoch 68/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3376 - val_loss: 0.3458 - lr: 0.0010\nEpoch 69/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3371 - val_loss: 0.3449 - lr: 0.0010\nEpoch 70/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3374 - val_loss: 0.3460 - lr: 0.0010\nFOLD 1\nEpoch 1/70\n24/24 [==============================] - 6s 258ms/step - loss: 0.4974 - val_loss: 0.4043 - lr: 0.0010\nEpoch 2/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3876 - val_loss: 0.3859 - lr: 0.0010\nEpoch 3/70\n","name":"stdout"},{"output_type":"stream","text":"24/24 [==============================] - 1s 36ms/step - loss: 0.3757 - val_loss: 0.3814 - lr: 0.0010\nEpoch 4/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3657 - val_loss: 0.3684 - lr: 0.0010\nEpoch 5/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3585 - val_loss: 0.3649 - lr: 0.0010\nEpoch 6/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3538 - val_loss: 0.3581 - lr: 0.0010\nEpoch 7/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3474 - val_loss: 0.3585 - lr: 0.0010\nEpoch 8/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3444 - val_loss: 0.3530 - lr: 0.0010\nEpoch 9/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3438 - val_loss: 0.3529 - lr: 0.0010\nEpoch 10/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3427 - val_loss: 0.3550 - lr: 0.0010\nEpoch 11/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3414 - val_loss: 0.3506 - lr: 0.0010\nEpoch 12/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3396 - val_loss: 0.3490 - lr: 0.0010\nEpoch 13/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3387 - val_loss: 0.3513 - lr: 0.0010\nEpoch 14/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3380 - val_loss: 0.3541 - lr: 0.0010\nEpoch 15/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3366 - val_loss: 0.3500 - lr: 0.0010\nEpoch 16/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3365 - val_loss: 0.3503 - lr: 0.0010\nEpoch 17/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3355 - val_loss: 0.3470 - lr: 0.0010\nEpoch 18/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3373 - val_loss: 0.3518 - lr: 0.0010\nEpoch 19/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3351 - val_loss: 0.3475 - lr: 0.0010\nEpoch 20/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3339 - val_loss: 0.3464 - lr: 0.0010\nEpoch 21/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3335 - val_loss: 0.3479 - lr: 0.0010\nEpoch 22/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.3329 - val_loss: 0.3454 - lr: 0.0010\nEpoch 23/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3322 - val_loss: 0.3461 - lr: 0.0010\nEpoch 24/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3315 - val_loss: 0.3451 - lr: 0.0010\nEpoch 25/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3325 - val_loss: 0.3487 - lr: 0.0010\nEpoch 26/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3307 - val_loss: 0.3459 - lr: 0.0010\nEpoch 27/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3309 - val_loss: 0.3458 - lr: 0.0010\nEpoch 28/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3310 - val_loss: 0.3429 - lr: 0.0010\nEpoch 29/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3295 - val_loss: 0.3468 - lr: 0.0010\nEpoch 30/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3290 - val_loss: 0.3431 - lr: 0.0010\nEpoch 31/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3284 - val_loss: 0.3478 - lr: 0.0010\nEpoch 32/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3286 - val_loss: 0.3448 - lr: 0.0010\nEpoch 33/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3286 - val_loss: 0.3441 - lr: 0.0010\nEpoch 34/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3281 - val_loss: 0.3425 - lr: 0.0010\nEpoch 35/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3274 - val_loss: 0.3433 - lr: 0.0010\nEpoch 36/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3264 - val_loss: 0.3417 - lr: 0.0010\nEpoch 37/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3274 - val_loss: 0.3445 - lr: 0.0010\nEpoch 38/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3264 - val_loss: 0.3411 - lr: 0.0010\nEpoch 39/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3264 - val_loss: 0.3423 - lr: 0.0010\nEpoch 40/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3266 - val_loss: 0.3467 - lr: 0.0010\nEpoch 41/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3255 - val_loss: 0.3408 - lr: 0.0010\nEpoch 42/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3255 - val_loss: 0.3405 - lr: 0.0010\nEpoch 43/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3246 - val_loss: 0.3402 - lr: 0.0010\nEpoch 44/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3242 - val_loss: 0.3409 - lr: 0.0010\nEpoch 45/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3257 - val_loss: 0.3426 - lr: 0.0010\nEpoch 46/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3244 - val_loss: 0.3395 - lr: 0.0010\nEpoch 47/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3243 - val_loss: 0.3388 - lr: 0.0010\nEpoch 48/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3239 - val_loss: 0.3461 - lr: 0.0010\nEpoch 49/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3223 - val_loss: 0.3393 - lr: 0.0010\nEpoch 50/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3222 - val_loss: 0.3390 - lr: 0.0010\nEpoch 51/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3229 - val_loss: 0.3425 - lr: 0.0010\nEpoch 52/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3226 - val_loss: 0.3389 - lr: 0.0010\nEpoch 53/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3220 - val_loss: 0.3372 - lr: 0.0010\nEpoch 54/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3218 - val_loss: 0.3358 - lr: 0.0010\nEpoch 55/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3215 - val_loss: 0.3390 - lr: 0.0010\nEpoch 56/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3202 - val_loss: 0.3394 - lr: 0.0010\nEpoch 57/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3200 - val_loss: 0.3392 - lr: 0.0010\nEpoch 58/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3201 - val_loss: 0.3365 - lr: 0.0010\nEpoch 59/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3196 - val_loss: 0.3373 - lr: 0.0010\nEpoch 60/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3199 - val_loss: 0.3373 - lr: 0.0010\nEpoch 61/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3202 - val_loss: 0.3455 - lr: 0.0010\nEpoch 62/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3200 - val_loss: 0.3350 - lr: 0.0010\nEpoch 63/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3184 - val_loss: 0.3343 - lr: 0.0010\nEpoch 64/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3183 - val_loss: 0.3377 - lr: 0.0010\nEpoch 65/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3186 - val_loss: 0.3350 - lr: 0.0010\nEpoch 66/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3171 - val_loss: 0.3343 - lr: 0.0010\nEpoch 67/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3175 - val_loss: 0.3363 - lr: 0.0010\nEpoch 68/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3167 - val_loss: 0.3335 - lr: 0.0010\nEpoch 69/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3169 - val_loss: 0.3342 - lr: 0.0010\nEpoch 70/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3170 - val_loss: 0.3353 - lr: 0.0010\nFOLD 2\nEpoch 1/70\n24/24 [==============================] - 6s 256ms/step - loss: 0.5807 - val_loss: 0.4169 - lr: 0.0010\nEpoch 2/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3896 - val_loss: 0.3832 - lr: 0.0010\nEpoch 3/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3633 - val_loss: 0.3613 - lr: 0.0010\nEpoch 4/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3461 - val_loss: 0.3491 - lr: 0.0010\nEpoch 5/70\n","name":"stdout"},{"output_type":"stream","text":"24/24 [==============================] - 1s 35ms/step - loss: 0.3344 - val_loss: 0.3433 - lr: 0.0010\nEpoch 6/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3304 - val_loss: 0.3475 - lr: 0.0010\nEpoch 7/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3277 - val_loss: 0.3382 - lr: 0.0010\nEpoch 8/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3240 - val_loss: 0.3345 - lr: 0.0010\nEpoch 9/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3224 - val_loss: 0.3324 - lr: 0.0010\nEpoch 10/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3212 - val_loss: 0.3325 - lr: 0.0010\nEpoch 11/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3207 - val_loss: 0.3297 - lr: 0.0010\nEpoch 12/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3206 - val_loss: 0.3320 - lr: 0.0010\nEpoch 13/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3197 - val_loss: 0.3369 - lr: 0.0010\nEpoch 14/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3187 - val_loss: 0.3313 - lr: 0.0010\nEpoch 15/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3180 - val_loss: 0.3306 - lr: 0.0010\nEpoch 16/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3172 - val_loss: 0.3389 - lr: 0.0010\nEpoch 17/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3176 - val_loss: 0.3305 - lr: 0.0010\nEpoch 18/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3157 - val_loss: 0.3291 - lr: 0.0010\nEpoch 19/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3167 - val_loss: 0.3285 - lr: 0.0010\nEpoch 20/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3164 - val_loss: 0.3297 - lr: 0.0010\nEpoch 21/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3157 - val_loss: 0.3283 - lr: 0.0010\nEpoch 22/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3146 - val_loss: 0.3300 - lr: 0.0010\nEpoch 23/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3139 - val_loss: 0.3268 - lr: 0.0010\nEpoch 24/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3140 - val_loss: 0.3272 - lr: 0.0010\nEpoch 25/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3137 - val_loss: 0.3292 - lr: 0.0010\nEpoch 26/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3126 - val_loss: 0.3275 - lr: 0.0010\nEpoch 27/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3128 - val_loss: 0.3297 - lr: 0.0010\nEpoch 28/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3132 - val_loss: 0.3274 - lr: 0.0010\nEpoch 29/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3125 - val_loss: 0.3323 - lr: 0.0010\nEpoch 30/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3141 - val_loss: 0.3303 - lr: 0.0010\nEpoch 31/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3124 - val_loss: 0.3268 - lr: 0.0010\nEpoch 32/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3125 - val_loss: 0.3251 - lr: 0.0010\nEpoch 33/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3106 - val_loss: 0.3250 - lr: 0.0010\nEpoch 34/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3105 - val_loss: 0.3251 - lr: 0.0010\nEpoch 35/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3104 - val_loss: 0.3268 - lr: 0.0010\nEpoch 36/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3106 - val_loss: 0.3263 - lr: 0.0010\nEpoch 37/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3090 - val_loss: 0.3245 - lr: 0.0010\nEpoch 38/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3095 - val_loss: 0.3257 - lr: 0.0010\nEpoch 39/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3091 - val_loss: 0.3274 - lr: 0.0010\nEpoch 40/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3085 - val_loss: 0.3281 - lr: 0.0010\nEpoch 41/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3100 - val_loss: 0.3259 - lr: 0.0010\nEpoch 42/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3088 - val_loss: 0.3274 - lr: 0.0010\nEpoch 43/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3093 - val_loss: 0.3294 - lr: 0.0010\nEpoch 44/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3080 - val_loss: 0.3254 - lr: 0.0010\nEpoch 45/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3085 - val_loss: 0.3243 - lr: 0.0010\nEpoch 46/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3090 - val_loss: 0.3266 - lr: 0.0010\nEpoch 47/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3077 - val_loss: 0.3244 - lr: 0.0010\nEpoch 48/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3066 - val_loss: 0.3233 - lr: 0.0010\nEpoch 49/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3065 - val_loss: 0.3228 - lr: 0.0010\nEpoch 50/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3082 - val_loss: 0.3300 - lr: 0.0010\nEpoch 51/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3076 - val_loss: 0.3255 - lr: 0.0010\nEpoch 52/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3055 - val_loss: 0.3222 - lr: 0.0010\nEpoch 53/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3056 - val_loss: 0.3222 - lr: 0.0010\nEpoch 54/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3049 - val_loss: 0.3233 - lr: 0.0010\nEpoch 55/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3060 - val_loss: 0.3224 - lr: 0.0010\nEpoch 56/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3051 - val_loss: 0.3247 - lr: 0.0010\nEpoch 57/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3045 - val_loss: 0.3242 - lr: 0.0010\nEpoch 58/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3039 - val_loss: 0.3218 - lr: 0.0010\nEpoch 59/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3045 - val_loss: 0.3231 - lr: 0.0010\nEpoch 60/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3044 - val_loss: 0.3255 - lr: 0.0010\nEpoch 61/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3040 - val_loss: 0.3229 - lr: 0.0010\nEpoch 62/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3039 - val_loss: 0.3223 - lr: 0.0010\nEpoch 63/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3046 - val_loss: 0.3229 - lr: 0.0010\nEpoch 64/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3058 - val_loss: 0.3220 - lr: 0.0010\nEpoch 65/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3038 - val_loss: 0.3219 - lr: 0.0010\nEpoch 66/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3034 - val_loss: 0.3213 - lr: 0.0010\nEpoch 67/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3030 - val_loss: 0.3272 - lr: 0.0010\nEpoch 68/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3029 - val_loss: 0.3211 - lr: 0.0010\nEpoch 69/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3035 - val_loss: 0.3234 - lr: 0.0010\nEpoch 70/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3033 - val_loss: 0.3216 - lr: 0.0010\nFOLD 3\nEpoch 1/70\n24/24 [==============================] - 6s 260ms/step - loss: 0.4364 - val_loss: 0.3656 - lr: 0.0010\nEpoch 2/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3402 - val_loss: 0.3429 - lr: 0.0010\nEpoch 3/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3256 - val_loss: 0.3349 - lr: 0.0010\nEpoch 4/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3199 - val_loss: 0.3352 - lr: 0.0010\nEpoch 5/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3168 - val_loss: 0.3275 - lr: 0.0010\nEpoch 6/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3148 - val_loss: 0.3281 - lr: 0.0010\nEpoch 7/70\n","name":"stdout"},{"output_type":"stream","text":"24/24 [==============================] - 1s 36ms/step - loss: 0.3135 - val_loss: 0.3272 - lr: 0.0010\nEpoch 8/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3129 - val_loss: 0.3315 - lr: 0.0010\nEpoch 9/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3113 - val_loss: 0.3278 - lr: 0.0010\nEpoch 10/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3122 - val_loss: 0.3274 - lr: 0.0010\nEpoch 11/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3095 - val_loss: 0.3262 - lr: 0.0010\nEpoch 12/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3084 - val_loss: 0.3250 - lr: 0.0010\nEpoch 13/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3082 - val_loss: 0.3247 - lr: 0.0010\nEpoch 14/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3082 - val_loss: 0.3238 - lr: 0.0010\nEpoch 15/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3091 - val_loss: 0.3257 - lr: 0.0010\nEpoch 16/70\n24/24 [==============================] - 3s 126ms/step - loss: 0.3095 - val_loss: 0.3255 - lr: 0.0010\nEpoch 17/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3063 - val_loss: 0.3225 - lr: 0.0010\nEpoch 18/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3086 - val_loss: 0.3222 - lr: 0.0010\nEpoch 19/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3069 - val_loss: 0.3198 - lr: 0.0010\nEpoch 20/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3046 - val_loss: 0.3194 - lr: 0.0010\nEpoch 21/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3063 - val_loss: 0.3212 - lr: 0.0010\nEpoch 22/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3055 - val_loss: 0.3237 - lr: 0.0010\nEpoch 23/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3056 - val_loss: 0.3198 - lr: 0.0010\nEpoch 24/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3050 - val_loss: 0.3242 - lr: 0.0010\nEpoch 25/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3045 - val_loss: 0.3231 - lr: 0.0010\nEpoch 26/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3039 - val_loss: 0.3178 - lr: 0.0010\nEpoch 27/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3039 - val_loss: 0.3226 - lr: 0.0010\nEpoch 28/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.3031 - val_loss: 0.3208 - lr: 0.0010\nEpoch 29/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3043 - val_loss: 0.3206 - lr: 0.0010\nEpoch 30/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3034 - val_loss: 0.3186 - lr: 0.0010\nEpoch 31/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.3048 - val_loss: 0.3234 - lr: 0.0010\nEpoch 32/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3033 - val_loss: 0.3199 - lr: 0.0010\nEpoch 33/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3034 - val_loss: 0.3187 - lr: 0.0010\nEpoch 34/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3028 - val_loss: 0.3190 - lr: 0.0010\nEpoch 35/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3024 - val_loss: 0.3178 - lr: 0.0010\nEpoch 36/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3018 - val_loss: 0.3186 - lr: 0.0010\nEpoch 37/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.2989 - val_loss: 0.3159 - lr: 1.0000e-04\nEpoch 38/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2969 - val_loss: 0.3163 - lr: 1.0000e-04\nEpoch 39/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.2965 - val_loss: 0.3157 - lr: 1.0000e-04\nEpoch 40/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2961 - val_loss: 0.3159 - lr: 1.0000e-04\nEpoch 41/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2962 - val_loss: 0.3161 - lr: 1.0000e-04\nEpoch 42/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2962 - val_loss: 0.3161 - lr: 1.0000e-04\nEpoch 43/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2962 - val_loss: 0.3161 - lr: 1.0000e-04\nEpoch 44/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2959 - val_loss: 0.3161 - lr: 1.0000e-04\nEpoch 45/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2960 - val_loss: 0.3163 - lr: 1.0000e-04\nEpoch 46/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.2963 - val_loss: 0.3154 - lr: 1.0000e-04\nEpoch 47/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2956 - val_loss: 0.3169 - lr: 1.0000e-04\nEpoch 48/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.2958 - val_loss: 0.3148 - lr: 1.0000e-04\nEpoch 49/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.2957 - val_loss: 0.3141 - lr: 1.0000e-04\nEpoch 50/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2958 - val_loss: 0.3148 - lr: 1.0000e-04\nEpoch 51/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2951 - val_loss: 0.3165 - lr: 1.0000e-04\nEpoch 52/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2960 - val_loss: 0.3156 - lr: 1.0000e-04\nEpoch 53/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2956 - val_loss: 0.3143 - lr: 1.0000e-04\nEpoch 54/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2956 - val_loss: 0.3151 - lr: 1.0000e-04\nEpoch 55/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2953 - val_loss: 0.3165 - lr: 1.0000e-04\nEpoch 56/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2953 - val_loss: 0.3152 - lr: 1.0000e-04\nEpoch 57/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2952 - val_loss: 0.3152 - lr: 1.0000e-04\nEpoch 58/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2952 - val_loss: 0.3152 - lr: 1.0000e-04\nEpoch 59/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.2959 - val_loss: 0.3140 - lr: 1.0000e-04\nEpoch 60/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2956 - val_loss: 0.3152 - lr: 1.0000e-04\nEpoch 61/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2952 - val_loss: 0.3156 - lr: 1.0000e-04\nEpoch 62/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2952 - val_loss: 0.3154 - lr: 1.0000e-04\nEpoch 63/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2949 - val_loss: 0.3149 - lr: 1.0000e-04\nEpoch 64/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2949 - val_loss: 0.3147 - lr: 1.0000e-04\nEpoch 65/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.2954 - val_loss: 0.3171 - lr: 1.0000e-04\nEpoch 66/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.2950 - val_loss: 0.3140 - lr: 1.0000e-04\nEpoch 67/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.2947 - val_loss: 0.3147 - lr: 1.0000e-04\nEpoch 68/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2951 - val_loss: 0.3147 - lr: 1.0000e-04\nEpoch 69/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.2947 - val_loss: 0.3154 - lr: 1.0000e-04\nEpoch 70/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.2950 - val_loss: 0.3146 - lr: 1.0000e-05\nFOLD 4\nEpoch 1/70\n24/24 [==============================] - 6s 254ms/step - loss: 0.6021 - val_loss: 0.3922 - lr: 0.0010\nEpoch 2/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3674 - val_loss: 0.3561 - lr: 0.0010\nEpoch 3/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3343 - val_loss: 0.3368 - lr: 0.0010\nEpoch 4/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3205 - val_loss: 0.3343 - lr: 0.0010\nEpoch 5/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3159 - val_loss: 0.3325 - lr: 0.0010\nEpoch 6/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.3133 - val_loss: 0.3301 - lr: 0.0010\nEpoch 7/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.3128 - val_loss: 0.3278 - lr: 0.0010\nEpoch 8/70\n","name":"stdout"},{"output_type":"stream","text":"24/24 [==============================] - 1s 30ms/step - loss: 0.3111 - val_loss: 0.3284 - lr: 0.0010\nEpoch 9/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3107 - val_loss: 0.3299 - lr: 0.0010\nEpoch 10/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3099 - val_loss: 0.3279 - lr: 0.0010\nEpoch 11/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3091 - val_loss: 0.3280 - lr: 0.0010\nEpoch 12/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3090 - val_loss: 0.3272 - lr: 0.0010\nEpoch 13/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3080 - val_loss: 0.3279 - lr: 0.0010\nEpoch 14/70\n24/24 [==============================] - 1s 38ms/step - loss: 0.3075 - val_loss: 0.3247 - lr: 0.0010\nEpoch 15/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3069 - val_loss: 0.3268 - lr: 0.0010\nEpoch 16/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3078 - val_loss: 0.3241 - lr: 0.0010\nEpoch 17/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3078 - val_loss: 0.3274 - lr: 0.0010\nEpoch 18/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3075 - val_loss: 0.3245 - lr: 0.0010\nEpoch 19/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3066 - val_loss: 0.3248 - lr: 0.0010\nEpoch 20/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3063 - val_loss: 0.3265 - lr: 0.0010\nEpoch 21/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3056 - val_loss: 0.3289 - lr: 0.0010\nEpoch 22/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3059 - val_loss: 0.3233 - lr: 0.0010\nEpoch 23/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3059 - val_loss: 0.3235 - lr: 0.0010\nEpoch 24/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.3062 - val_loss: 0.3226 - lr: 0.0010\nEpoch 25/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3068 - val_loss: 0.3238 - lr: 0.0010\nEpoch 26/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.3064 - val_loss: 0.3197 - lr: 0.0010\nEpoch 27/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3059 - val_loss: 0.3212 - lr: 0.0010\nEpoch 28/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3047 - val_loss: 0.3258 - lr: 0.0010\nEpoch 29/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3056 - val_loss: 0.3241 - lr: 0.0010\nEpoch 30/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3065 - val_loss: 0.3229 - lr: 0.0010\nEpoch 31/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3056 - val_loss: 0.3222 - lr: 0.0010\nEpoch 32/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.3052 - val_loss: 0.3253 - lr: 0.0010\nEpoch 33/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3059 - val_loss: 0.3222 - lr: 0.0010\nEpoch 34/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3050 - val_loss: 0.3222 - lr: 0.0010\nEpoch 35/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.3045 - val_loss: 0.3230 - lr: 0.0010\nEpoch 36/70\n24/24 [==============================] - 1s 34ms/step - loss: 0.3044 - val_loss: 0.3205 - lr: 0.0010\nEpoch 37/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.3000 - val_loss: 0.3200 - lr: 1.0000e-04\nEpoch 38/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2992 - val_loss: 0.3197 - lr: 1.0000e-04\nEpoch 39/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.2987 - val_loss: 0.3195 - lr: 1.0000e-04\nEpoch 40/70\n24/24 [==============================] - 1s 39ms/step - loss: 0.2987 - val_loss: 0.3191 - lr: 1.0000e-04\nEpoch 41/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2986 - val_loss: 0.3192 - lr: 1.0000e-04\nEpoch 42/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.2982 - val_loss: 0.3181 - lr: 1.0000e-04\nEpoch 43/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.2982 - val_loss: 0.3173 - lr: 1.0000e-04\nEpoch 44/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.2980 - val_loss: 0.3180 - lr: 1.0000e-04\nEpoch 45/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.2979 - val_loss: 0.3170 - lr: 1.0000e-04\nEpoch 46/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.2978 - val_loss: 0.3174 - lr: 1.0000e-04\nEpoch 47/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.2982 - val_loss: 0.3167 - lr: 1.0000e-04\nEpoch 48/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2980 - val_loss: 0.3175 - lr: 1.0000e-04\nEpoch 49/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.2977 - val_loss: 0.3163 - lr: 1.0000e-04\nEpoch 50/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2980 - val_loss: 0.3185 - lr: 1.0000e-04\nEpoch 51/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2976 - val_loss: 0.3174 - lr: 1.0000e-04\nEpoch 52/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2976 - val_loss: 0.3168 - lr: 1.0000e-04\nEpoch 53/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2975 - val_loss: 0.3173 - lr: 1.0000e-04\nEpoch 54/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.2975 - val_loss: 0.3175 - lr: 1.0000e-04\nEpoch 55/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2977 - val_loss: 0.3177 - lr: 1.0000e-04\nEpoch 56/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.2977 - val_loss: 0.3165 - lr: 1.0000e-04\nEpoch 57/70\n24/24 [==============================] - 1s 36ms/step - loss: 0.2975 - val_loss: 0.3161 - lr: 1.0000e-04\nEpoch 58/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2974 - val_loss: 0.3177 - lr: 1.0000e-04\nEpoch 59/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2977 - val_loss: 0.3166 - lr: 1.0000e-04\nEpoch 60/70\n24/24 [==============================] - 1s 30ms/step - loss: 0.2968 - val_loss: 0.3183 - lr: 1.0000e-04\nEpoch 61/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2973 - val_loss: 0.3168 - lr: 1.0000e-04\nEpoch 62/70\n24/24 [==============================] - 1s 35ms/step - loss: 0.2977 - val_loss: 0.3160 - lr: 1.0000e-04\nEpoch 63/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2972 - val_loss: 0.3177 - lr: 1.0000e-04\nEpoch 64/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2974 - val_loss: 0.3166 - lr: 1.0000e-04\nEpoch 65/70\n24/24 [==============================] - 1s 31ms/step - loss: 0.2978 - val_loss: 0.3168 - lr: 1.0000e-04\nEpoch 66/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.2971 - val_loss: 0.3163 - lr: 1.0000e-04\nEpoch 67/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.2963 - val_loss: 0.3164 - lr: 1.0000e-04\nEpoch 68/70\n24/24 [==============================] - 1s 37ms/step - loss: 0.2969 - val_loss: 0.3158 - lr: 1.0000e-04\nEpoch 69/70\n24/24 [==============================] - 1s 32ms/step - loss: 0.2970 - val_loss: 0.3167 - lr: 1.0000e-04\nEpoch 70/70\n24/24 [==============================] - 1s 33ms/step - loss: 0.2975 - val_loss: 0.3171 - lr: 1.0000e-04\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = pd.DataFrame({ \"loss\": history.history['loss'], \"val_loss\": history.history['val_loss']})","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history","execution_count":70,"outputs":[{"output_type":"execute_result","execution_count":70,"data":{"text/plain":"{'loss': [0.6021100878715515,\n  0.36736220121383667,\n  0.3342948257923126,\n  0.3205300569534302,\n  0.31591367721557617,\n  0.31333860754966736,\n  0.31280264258384705,\n  0.3111133575439453,\n  0.3106634318828583,\n  0.3098655045032501,\n  0.30914419889450073,\n  0.3090193271636963,\n  0.3079523742198944,\n  0.30750784277915955,\n  0.3069045841693878,\n  0.30783966183662415,\n  0.3078019320964813,\n  0.3075067698955536,\n  0.30664005875587463,\n  0.306295245885849,\n  0.3056457042694092,\n  0.305927574634552,\n  0.30593788623809814,\n  0.3062324523925781,\n  0.3067706227302551,\n  0.3063541650772095,\n  0.30587038397789,\n  0.3046576678752899,\n  0.3056255877017975,\n  0.3065192997455597,\n  0.3055943548679352,\n  0.3052004873752594,\n  0.305929034948349,\n  0.3049778938293457,\n  0.3045072853565216,\n  0.30440130829811096,\n  0.30002036690711975,\n  0.2992188036441803,\n  0.29867100715637207,\n  0.29874736070632935,\n  0.29858896136283875,\n  0.2981647551059723,\n  0.29819434881210327,\n  0.2979615032672882,\n  0.29791656136512756,\n  0.29779088497161865,\n  0.29816219210624695,\n  0.29802051186561584,\n  0.29766255617141724,\n  0.297976016998291,\n  0.2975800931453705,\n  0.29764342308044434,\n  0.2974884808063507,\n  0.2974500060081482,\n  0.29772546887397766,\n  0.29766038060188293,\n  0.2975284159183502,\n  0.2973891496658325,\n  0.2977043688297272,\n  0.2968313992023468,\n  0.2972673177719116,\n  0.2976817786693573,\n  0.2971782684326172,\n  0.29741916060447693,\n  0.29778236150741577,\n  0.2970793843269348,\n  0.2962910830974579,\n  0.29687339067459106,\n  0.2969895005226135,\n  0.297514408826828],\n 'val_loss': [0.3922137916088104,\n  0.3561316132545471,\n  0.336832195520401,\n  0.33428674936294556,\n  0.3325098752975464,\n  0.33006954193115234,\n  0.32778865098953247,\n  0.3284394145011902,\n  0.3299112021923065,\n  0.32794541120529175,\n  0.3279707133769989,\n  0.3272019922733307,\n  0.32790449261665344,\n  0.32466980814933777,\n  0.3267779052257538,\n  0.3241099715232849,\n  0.3274497985839844,\n  0.3245038688182831,\n  0.3247511684894562,\n  0.326452374458313,\n  0.3288554847240448,\n  0.3232925534248352,\n  0.32354655861854553,\n  0.32260528206825256,\n  0.3237520456314087,\n  0.31968238949775696,\n  0.3212428689002991,\n  0.3257623314857483,\n  0.32407379150390625,\n  0.3228934705257416,\n  0.3221818804740906,\n  0.3252623677253723,\n  0.32224127650260925,\n  0.3221876919269562,\n  0.3229658007621765,\n  0.3204750120639801,\n  0.3199559152126312,\n  0.3196920156478882,\n  0.31946882605552673,\n  0.31914135813713074,\n  0.3191719651222229,\n  0.3180966079235077,\n  0.31726011633872986,\n  0.31795069575309753,\n  0.3169827163219452,\n  0.31740912795066833,\n  0.31665173172950745,\n  0.31745943427085876,\n  0.31627777218818665,\n  0.31848257780075073,\n  0.3173765540122986,\n  0.31677886843681335,\n  0.3172838091850281,\n  0.3174588084220886,\n  0.3176591098308563,\n  0.3164575397968292,\n  0.3161410391330719,\n  0.3176591992378235,\n  0.3166077136993408,\n  0.31826555728912354,\n  0.31684643030166626,\n  0.316018283367157,\n  0.3176678717136383,\n  0.3165507912635803,\n  0.3167850077152252,\n  0.31627196073532104,\n  0.31640926003456116,\n  0.3158320486545563,\n  0.3166709542274475,\n  0.3170958161354065],\n 'lr': [0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.001,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005,\n  0.000100000005]}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nloss.plot()","execution_count":71,"outputs":[{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f540b492d90>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_bert = []\n\nfor df, preds in [(public_df, bert_public_preds), (private_df, bert_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_bert.append(single_df)\n\npreds_bert_df = pd.concat(preds_bert)\npreds_bert_df.head()\n","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"   reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  deg_50C       id_seqpos\n0         0.0          0.0       0.0         0.0      0.0  id_00073f8be_0\n1         0.0          0.0       0.0         0.0      0.0  id_00073f8be_1\n2         0.0          0.0       0.0         0.0      0.0  id_00073f8be_2\n3         0.0          0.0       0.0         0.0      0.0  id_00073f8be_3\n4         0.0          0.0       0.0         0.0      0.0  id_00073f8be_4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reactivity</th>\n      <th>deg_Mg_pH10</th>\n      <th>deg_pH10</th>\n      <th>deg_Mg_50C</th>\n      <th>deg_50C</th>\n      <th>id_seqpos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_00073f8be_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_00073f8be_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_00073f8be_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_00073f8be_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_00073f8be_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sub[['id_seqpos']].merge(preds_bert_df, on=['id_seqpos'])\nsubmission.to_csv('submission3.csv', index=False)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}